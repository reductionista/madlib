# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import plpy

import keras
import time
from keras import backend as K
from keras.layers import *
from keras.models import *
from keras.optimizers import *

from model_arch_info import *
from madlib_keras_helper import *
from madlib_keras_validator import *
from predict_input_params import PredictParamsProcessor
from utilities.control import MinWarning
from utilities.utilities import _assert
from utilities.utilities import add_postfix
from utilities.utilities import create_cols_from_array_sql_string
from utilities.utilities import get_segments_per_host
from utilities.utilities import unique_string
from utilities.validate_args import input_tbl_valid
from utilities.validate_args import quote_ident

from madlib_keras_wrapper import *

class BasePredict():
    def __init__(self, schema_madlib, table_to_validate, test_table, id_col,
                 independent_varname, output_table, pred_type, gpus_per_host):
        self.schema_madlib = schema_madlib
        self.table_to_validate = table_to_validate
        self.test_table = test_table
        self.id_col = id_col
        self.independent_varname = independent_varname
        self.output_table = output_table
        self.pred_type = pred_type
        self.gpus_per_host = gpus_per_host
        self._set_default_gpus_pred_type()

    def _set_default_gpus_pred_type(self):
        self.pred_type =  'response' if not self.pred_type else self.pred_type
        self.is_response = True if self.pred_type == 'response' else False
        self.gpus_per_host = 0 if self.gpus_per_host is None else self.gpus_per_host


    def call_internal_keras(self):
        if self.is_response:
            pred_col_name = add_postfix("estimated_", self.dependent_varname)
            pred_col_type = self.dependent_vartype
        else:
            pred_col_name = "prob"
            pred_col_type = 'double precision'

        intermediate_col = unique_string()
        class_values = strip_trailing_nulls_from_class_values(self.class_values)

        prediction_select_clause = create_cols_from_array_sql_string(
            class_values, intermediate_col, pred_col_name,
            pred_col_type, self.is_response, self.module_name)
        gp_segment_id_col, seg_ids_test, \
        images_per_seg_test = get_image_count_per_seg_for_non_minibatched_data_from_db(
            self.test_table)
        segments_per_host = get_segments_per_host()

        ## Set GD on 2 Slices via JOIN
        set_gd_query=plpy.prepare("""
                    Select * from 
                   (SELECT {self.schema_madlib}.internal_set_predict_GD
                    ($MAD${self.model_arch}$MAD$::text,
                    $1,
                    {self.is_response},
                    {self.normalizing_const}::double precision,
                    ARRAY{seg_ids_test},
                    ARRAY{images_per_seg_test},
                    {self.gpus_per_host},
                    {segments_per_host}
                    ) from gp_dist_random('gp_id')) t1
                    JOIN
                    (SELECT {self.schema_madlib}.internal_set_predict_GD
                    ($MAD${self.model_arch}$MAD$::text,
                    $1,
                    {self.is_response},
                    {self.normalizing_const}::double precision,
                    ARRAY{seg_ids_test},
                    ARRAY{images_per_seg_test},
                    {self.gpus_per_host},
                    {segments_per_host}
                    ) from gp_dist_random('gp_id')) t2 on true
                    """.format(self=self, seg_ids_test=seg_ids_test,
                               images_per_seg_test=images_per_seg_test,
                               segments_per_host=segments_per_host),
                        ["bytea"]) #Using gp_dist_random('gp_id')

#        set_gd_query_once=plpy.prepare("""
#                   SELECT {self.schema_madlib}.internal_set_predict_GD
#                    ($MAD${self.model_arch}$MAD$::text,
#                    $1,
#                    {self.is_response},
#                    {self.normalizing_const}::double precision,
#                    ARRAY{seg_ids_test},
#                    ARRAY{images_per_seg_test},
#                    {self.gpus_per_host},
#                    {segments_per_host}
#                    ) from gp_dist_random('gp_id')
#                    """.format(self=self, seg_ids_test=seg_ids_test,
#                        images_per_seg_test=images_per_seg_test,
#                        segments_per_host=segments_per_host),
#                    ["bytea"])
#
#        start_time = time.time();
#        plpy.execute(set_gd_query_once, [self.model_weights])
#        plpy.info("SetGD time single_call: {}".format(time.time() - start_time))
        
        start_time = time.time();
        plpy.execute(set_gd_query, [self.model_weights])
        plpy.info("SetGD time join_call: {}".format(time.time() - start_time))


        plpy.execute("""
                CREATE TEMP TABLE tt AS        
                SELECT {self.test_table}.{self.id_col},
                       ({self.schema_madlib}.internal_keras_predict
                           ({self.independent_varname}, {gp_segment_id_col})
                       ) AS {intermediate_col}
            FROM {self.test_table}
            """.format(self=self,
                       gp_segment_id_col=gp_segment_id_col,
                       intermediate_col=intermediate_col))
        plpy.execute("""
                CREATE TABLE {self.output_table} AS
                SELECT {self.id_col}, {prediction_select_clause}
                from tt""".format(self=self, prediction_select_clause=prediction_select_clause))
        plpy.execute("DROP TABLE tt")

# TODO
#        plpy.execute("""
#            CREATE TABLE {self.output_table} ({self.id_col} INTEGER,
#                {prediction_select_clause} REAL[]) VALUES
#                (  {res}   )
#                SELECT {self.id_col}, {prediction_select_clause}
#                    ) q distributed by ({self.id_col})
#        """.format(self=self,
#                   prediction_select_clause=prediction_select_clause))

#        predict_query = plpy.prepare("""
#            CREATE TABLE {self.output_table} AS
#            SELECT {self.id_col}, {prediction_select_clause}
#            FROM (
#                SELECT {self.test_table}.{self.id_col},
#                       ({self.schema_madlib}.internal_keras_predict
#                           ({self.independent_varname},
#                            $1,
#                            $2,
#                            {self.is_response},
#                            {self.normalizing_const},
##                            {gp_segment_id_col},
#                            ARRAY{seg_ids_test},
#                            ARRAY{images_per_seg_test},
#                            {self.gpus_per_host},
#                            {segments_per_host})
#                       ) AS {intermediate_col}
#            FROM {self.test_table}
#            ) q
#            """.format(self=self, prediction_select_clause=prediction_select_clause,
#                       seg_ids_test=seg_ids_test,
#                       images_per_seg_test=images_per_seg_test,
#                       gp_segment_id_col=gp_segment_id_col,
#                       segments_per_host=segments_per_host,
#                       intermediate_col=intermediate_col),
#                                     ["text", "bytea"])
#        plpy.execute(predict_query, [model_arch, self.model_weights])

    def set_default_class_values(self, class_values):
        self.class_values = class_values
        if self.pred_type == 'prob':
            return
        if self.class_values is None:
            num_classes = get_num_classes(self.model_arch)
            self.class_values = range(0, num_classes)

@MinWarning("warning")
class Predict(BasePredict):
    def __init__(self, schema_madlib, model_table,
                 test_table, id_col, independent_varname,
                 output_table, pred_type, gpus_per_host,
                 **kwargs):

        self.module_name = 'madlib_keras_predict'
        self.model_table = model_table
        if self.model_table:
            self.model_summary_table = add_postfix(self.model_table, "_summary")

        BasePredict.__init__(self, schema_madlib, model_table, test_table,
                              id_col, independent_varname,
                              output_table, pred_type,
                              gpus_per_host)
        param_proc = PredictParamsProcessor(model_table, self.module_name)
        self.dependent_vartype = param_proc.get_dependent_vartype()
        self.model_weights = param_proc.get_model_data()
        self.model_arch = param_proc.get_model_arch()
        class_values = param_proc.get_class_values()
        self.set_default_class_values(class_values)
        self.normalizing_const = param_proc.get_normalizing_const()
        self.dependent_varname = param_proc.get_dependent_varname()

        self.validate()
        BasePredict.call_internal_keras(self)

    def validate(self):
        InputValidator.validate_predict_evaluate_tables(
            self.module_name, self.model_table, self.model_summary_table,
            self.test_table, self.output_table, self.independent_varname)

        InputValidator.validate_id_in_test_tbl(
            self.module_name, self.test_table, self.id_col)

        InputValidator.validate_class_values(
            self.module_name, self.class_values, self.pred_type, self.model_arch)
        input_shape = get_input_shape(self.model_arch)
        InputValidator.validate_pred_type(
            self.module_name, self.pred_type, self.class_values)
        InputValidator.validate_input_shape(
            self.test_table, self.independent_varname, input_shape, 1)

def set_predict_GD(model_architecture, model_data,
                   is_response, normalizing_const, seg_ids,
                   images_per_seg, gpus_per_host, segments_per_host,
                   **kwargs):
    GD = kwargs['GD']
    GD['model_architecture'] = model_architecture
    GD['model_data'] = model_data
    GD['is_response'] = is_response
    GD['normalizing_const'] = normalizing_const
    GD['seg_ids'] = seg_ids
    GD['images_per_seg'] = images_per_seg
    GD['gpus_per_host'] = gpus_per_host
    GD['segments_per_host'] = segments_per_host


@MinWarning("warning")
class PredictBYOM(BasePredict):
    def __init__(self, schema_madlib, model_arch_table, model_arch_id,
                 test_table, id_col, independent_varname, output_table,
                 pred_type, gpus_per_host, class_values, normalizing_const,
                 **kwargs):

        self.module_name='madlib_keras_predict_byom'
        self.model_arch_table = model_arch_table
        self.model_arch_id = model_arch_id
        self.class_values = class_values
        self.normalizing_const = normalizing_const
        self.dependent_varname = 'dependent_var'
        BasePredict.__init__(self, schema_madlib, model_arch_table,
                             test_table, id_col, independent_varname,
                             output_table, pred_type, gpus_per_host)
        if self.is_response:
            self.dependent_vartype = 'text'
        else:
            self.dependent_vartype = 'double precision'
        ## Set default values for norm const and class_values
        # gpus_per_host and pred_type are defaulted in base_predict's init
        self.normalizing_const = normalizing_const
        if self.normalizing_const is None:
            self.normalizing_const = DEFAULT_NORMALIZING_CONST
        InputValidator.validate_predict_byom_tables(
            self.module_name, self.model_arch_table, self.model_arch_id,
            self.test_table, self.id_col, self.output_table,
            self.independent_varname)
        self.validate_and_set_defaults()
        BasePredict.call_internal_keras(self)

    def validate_and_set_defaults(self):
        # Set some defaults first and then validate and then set some more defaults
        self.model_arch, self.model_weights = get_model_arch_weights(
            quote_ident(self.model_arch_table), self.model_arch_id)
        # Assert model_weights and model_arch are not empty.
        _assert(self.model_weights and self.model_arch,
                "{0}: Model weights and architecture should not be NULL.".format(
                    self.module_name))
        self.set_default_class_values(self.class_values)

        InputValidator.validate_pred_type(
            self.module_name, self.pred_type, self.class_values)
        InputValidator.validate_normalizing_const(
            self.module_name, self.normalizing_const)
        InputValidator.validate_class_values(
            self.module_name, self.class_values, self.pred_type, self.model_arch)
        InputValidator.validate_input_shape(
            self.test_table, self.independent_varname,
            get_input_shape(self.model_arch), 1)

#def internal_keras_predict(independent_var, model_architecture, model_data,
#                           is_response, normalizing_const, current_seg_id, seg_ids,
#                           images_per_seg, gpus_per_host, segments_per_host,
#                           **kwargs):

def internal_keras_predict(independent_var, current_seg_id, **kwargs):
    model_key = 'segment_model_predict'
    row_count_key = 'row_count'

    SD = kwargs['SD']
    GD = kwargs['GD']
    model_data = GD['model_data']
    model_architecture = GD['model_architecture']
    is_response = GD['is_response']
    normalizing_const = GD['normalizing_const']
    seg_ids = GD['seg_ids']
    images_per_seg = GD['images_per_seg']
    gpus_per_host = GD['gpus_per_host']
    segments_per_host = GD['segments_per_host']

    try:
        device_name = get_device_name_and_set_cuda_env(gpus_per_host,
                                                       current_seg_id)
        if model_key not in SD:
            set_keras_session(device_name, gpus_per_host, segments_per_host)
            model = model_from_json(model_architecture)
            model_shapes = get_model_shapes(model)
            set_model_weights(model, device_name, model_data, model_shapes)

            SD[model_key] = model
            SD[row_count_key] = 0
        else:
            model = SD[model_key]
        SD[row_count_key] += 1

        # Since the test data isn't mini-batched,
        # we have to make sure that the test data np array has the same
        # number of dimensions as input_shape. So we add a dimension to x.
        independent_var = expand_input_dims(independent_var)
        independent_var /= normalizing_const

        if is_response:
            with K.tf.device(device_name):
                y_prob = model.predict(independent_var)
                proba_argmax = y_prob.argmax(axis=-1)
            # proba_argmax is a list with exactly one element in it. That element
            # refers to the index containing the largest probability value in the
            # output of Keras' predict function.
            result = proba_argmax
        else:
            with K.tf.device(device_name):
                probs = model.predict(independent_var)
            # probs is a list containing a list of probability values, of all
            # class levels. Since we are assuming each input is a single image,
            # and not mini-batched, this list contains exactly one list in it,
            # so return back the first list in probs.
            result = probs[0]
        total_images = get_image_count_per_seg_from_array(current_seg_id, seg_ids,
                                                          images_per_seg)

        if SD[row_count_key] == total_images:
            SD.pop(model_key, None)
            SD.pop(row_count_key, None)
            clear_keras_session()
        return result
    except Exception as ex:
        SD.pop(model_key, None)
        SD.pop(row_count_key, None)
        clear_keras_session()
        plpy.error(ex)


def predict_help(schema_madlib, message, **kwargs):
    """
    Help function for keras predict

    Args:
        @param schema_madlib
        @param message: string, Help message string
        @param kwargs

    Returns:
        String. Help/usage information
    """
    if not message:
        help_string = """
-----------------------------------------------------------------------
                            SUMMARY
-----------------------------------------------------------------------
This function allows the user to predict using a madlib_keras_fit trained
model.

For more details on function usage:
    SELECT {schema_madlib}.madlib_keras_predict('usage')
            """
    elif message in ['usage', 'help', '?']:
        help_string = """
-----------------------------------------------------------------------
                            USAGE
-----------------------------------------------------------------------
 SELECT {schema_madlib}.madlib_keras_predict(
    model_table,    --  Name of the table containing the model
    test_table,     --  Name of the table containing the evaluation dataset
    id_col,         --  Name of the id column in the test data table
    independent_varname,    --  Name of the column with independent
                                variables in the test table
    output_table,   --  Name of the output table
    pred_type,      --  The type of the desired output
    gpus_per_host   --  Number of GPUs per segment host to
                        be used for training
    )
 );

-----------------------------------------------------------------------
                            OUTPUT
-----------------------------------------------------------------------
The output table ('output_table' above) contains the following columns:

id:                 Gives the 'id' for each prediction, corresponding
                    to each row from the test_table.
estimated_COL_NAME: (For pred_type='response') The estimated class for
                    classification, where COL_NAME is the name of the
                    column to be predicted from test data.
prob_CLASS:         (For pred_type='prob' for classification) The
                    probability of a given class. There will be one
                    column for each class in the training data.
                    TODO change this
"""
    else:
        help_string = "No such option. Use {schema_madlib}.madlib_keras_predict()"

    return help_string.format(schema_madlib=schema_madlib)

def predict_byom_help(schema_madlib, message, **kwargs):
    """
    Help function for keras predict

    Args:
        @param schema_madlib
        @param message: string, Help message string
        @param kwargs

    Returns:
        String. Help/usage information
    """
    if not message:
        help_string = """
-----------------------------------------------------------------------
                            SUMMARY
-----------------------------------------------------------------------
This function allows the user to predict with their own pre trained model (note
that this model doesn't have to be trained using MADlib.)

For more details on function usage:
    SELECT {schema_madlib}.madlib_keras_predict_byom('usage')
            """
    elif message in ['usage', 'help', '?']:
        help_string = """
-----------------------------------------------------------------------
                            USAGE
-----------------------------------------------------------------------
 SELECT {schema_madlib}.madlib_keras_predict_byom(
    model_arch_table, -- Name of the table containing the model architecture
                            and the pre trained model weights
    model_arch_id,    -- This is the id in 'model_arch_table' containing the
                         model architecture
    test_table,     --  Name of the table containing the evaluation dataset
    id_col,         --  Name of the id column in the test data table
    independent_varname,    --  Name of the column with independent
                                variables in the test table
    output_table,   --  Name of the output table
    pred_type,      --  The type of the desired output
    gpus_per_host,   --  Number of GPUs per segment host to
                        be used for training
    class_values,     -- List of class labels that were used while training the 
                         model. If class_values is passed in as NULL, the output
                         table will have a column named 'prob' which is an array
                         of probabilities of all the classes.
                         Otherwise if class_values is not NULL, then the output
                         table will contain a column for each class/label from
                         the training data
    normalizing_const -- Normalizing constant used for standardizing arrays in 
                         independent_varname
    )
 );

-----------------------------------------------------------------------
                            OUTPUT
-----------------------------------------------------------------------
The output table ('output_table' above) contains the following columns:

id:                 Gives the 'id' for each prediction, corresponding
                    to each row from the test_table.
estimated_dependent_var: (For pred_type='response') The estimated class for
                    classification. If class_values is passed in as NULL, then we
                    assume that the class labels are [0,1,2...,n] where n in the
                    num of classes in the model architecture.
prob_CLASS:         (For pred_type='prob' for classification) The
                    probability of a given class.
                    If class_values is passed in as NULL, we create just one column
                    called 'prob' which is an array of probabilites of all the classes
                    Otherwise if class_values is not NULL, then there will be one
                    column for each class in the training data.
"""
    else:
        help_string = "No such option. Use {schema_madlib}.madlib_keras_predict_byom()"

    return help_string.format(schema_madlib=schema_madlib)
# ---------------------------------------------------------------------
