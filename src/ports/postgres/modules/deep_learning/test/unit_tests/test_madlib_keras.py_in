# coding=utf-8
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

import sys
import numpy as np
from os import path
# Add convex module to the pythonpath.
sys.path.append(path.dirname(path.dirname(path.dirname(path.dirname(path.abspath(__file__))))))
sys.path.append(path.dirname(path.dirname(path.dirname(path.abspath(__file__)))))

import keras
from keras.models import *
from keras.layers import *
import unittest
from mock import *
import plpy_mock as plpy

m4_changequote(`<!', `!>')

# helper for multiplying array by int
def mult(k,arr):
    return [ k*a for a in arr ]

class MadlibKerasFitTestCase(unittest.TestCase):
    def setUp(self):
        self.plpy_mock = Mock(spec='error')
        patches = {
            'plpy': plpy
        }

        self.plpy_mock_execute = MagicMock()
        plpy.execute = self.plpy_mock_execute

        self.module_patcher = patch.dict('sys.modules', patches)
        self.module_patcher.start()
        import madlib_keras
        self.subject = madlib_keras

        self.model = Sequential()
        self.model.add(Conv2D(2, kernel_size=(1, 1), activation='relu',
                         input_shape=(1,1,1,), padding='same'))
        self.model.add(Flatten())

        self.compile_params = "optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy']"
        self.fit_params = "batch_size=1, epochs=1"
        self.model_weights = [3,4,5,6]
        self.model_shapes = []
        for a in self.model.get_weights():
            self.model_shapes.append(a.shape)

        self.loss = 13.0
        self.accuracy = 3.4
        self.all_seg_ids = [0,1,2]

        self.independent_var = [[[[0.5]]]] * 10
        self.dependent_var = [[0,1]] * 10
        # We test on segment 0, which has 3 buffers filled with 10 identical
        #  images each, or 30 images total
        self.total_images_per_seg = [3*len(self.dependent_var),20,40]

    def tearDown(self):
        self.module_patcher.stop()

    def test_fit_transition_first_buffer_pass_pg(self):
        #TODO should we mock tensorflow's close_session and keras'
        # clear_session instead of mocking the function `clear_keras_session`

        #postgres
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()
        self.subject.is_platform_pg = Mock(return_value = True)
        starting_image_count = 0
        ending_image_count = len(self.dependent_var)
        previous_state = [self.loss, self.accuracy, starting_image_count]
        previous_state.extend(self.model_weights)
        previous_state = np.array(previous_state, dtype=np.float32)

        k = {'SD' : {}}

        new_model_state = self.subject.fit_transition(
            None, self.independent_var , self.dependent_var, 0, 2, self.all_seg_ids, self.total_images_per_seg,
            self.model.to_json(), self.compile_params, self.fit_params, False,
            previous_state.tostring(), **k)
        state = np.fromstring(new_model_state, dtype=np.float32)
        image_count = state[2]
        weights = np.rint(state[3:]).astype(np.int)
        self.assertEqual(ending_image_count, image_count)
        # weights should not be modified yet
        self.assertTrue((self.model_weights == weights).all())
        # set_session must be not be called in transition func for PG
        self.assertEqual(0, self.subject.K.set_session.call_count)
        # Clear session and sess.close must not get called for the first buffer
        self.assertEqual(0, self.subject.clear_keras_session.call_count)
        self.assertTrue(k['SD']['segment_model'])
        self.assertTrue(k['SD']['model_shapes'])

    def test_fit_transition_first_buffer_pass_gpdb(self):
        #TODO should we mock tensorflow's close_session and keras'
        # clear_session instead of mocking the function `clear_keras_session`

        #postgres
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()
        self.subject.is_platform_pg = Mock(return_value = False)
        starting_image_count = 0
        ending_image_count = len(self.dependent_var)
        previous_state = [self.loss, self.accuracy, starting_image_count]
        previous_state.extend(self.model_weights)
        previous_state = np.array(previous_state, dtype=np.float32)

        k = {'SD' : {}}

        new_model_state = self.subject.fit_transition(
            None, self.independent_var , self.dependent_var, 0, 2, self.all_seg_ids, self.total_images_per_seg,
            self.model.to_json(), self.compile_params, self.fit_params, False,
            previous_state.tostring(), **k)
        state = np.fromstring(new_model_state, dtype=np.float32)
        image_count = state[2]
        weights = np.rint(state[3:]).astype(np.int)
        self.assertEqual(ending_image_count, image_count)
        # weights should not be modified yet
        self.assertTrue((self.model_weights == weights).all())
        # set_session must get called ONLY once, when its the first buffer
        self.assertEqual(1, self.subject.K.set_session.call_count)
        # Clear session and sess.close must not get called for the first buffer
        self.assertEqual(0, self.subject.clear_keras_session.call_count)
        self.assertTrue(k['SD']['segment_model'])
        self.assertTrue(k['SD']['model_shapes'])

    def test_fit_transition_middle_buffer_pass(self):
        #TODO should we mock tensorflow's close_session and keras'
        # clear_session instead of mocking the function `clear_keras_session`
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()
        self.subject.is_platform_pg = Mock(return_value = False)

        starting_image_count = len(self.dependent_var)
        ending_image_count = starting_image_count + len(self.dependent_var)

        state = [self.loss, self.accuracy, starting_image_count]
        state.extend(self.model_weights)
        state = np.array(state, dtype=np.float32)

        self.subject.compile_and_set_weights(self.model, self.compile_params,
                                             '/cpu:0', state.tostring(), self.model_shapes)
        k = {'SD': {'model_shapes': self.model_shapes}}
        k['SD']['segment_model'] = self.model

        new_model_state = self.subject.fit_transition(
            state.tostring(), self.independent_var, self.dependent_var, 0, 2, self.all_seg_ids, self.total_images_per_seg,
            self.model.to_json(), None, self.fit_params, False, 'dummy_previous_state', **k)

        state = np.fromstring(new_model_state, dtype=np.float32)
        image_count = state[2]
        weights = np.rint(state[3:]).astype(np.int)
        self.assertEqual(ending_image_count, image_count)
        # weights should not be modified yet
        self.assertTrue((self.model_weights == weights).all())
        # set_session must get called ONLY once, when its the first buffer
        self.assertEqual(0, self.subject.K.set_session.call_count)
        # Clear session and sess.close must not get called for the middle buffer
        self.assertEqual(0, self.subject.clear_keras_session.call_count)

    def test_fit_transition_last_buffer_pass_pg(self):
        #TODO should we mock tensorflow's close_session and keras'
        # clear_session instead of mocking the function `clear_keras_session`
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()
        self.subject.is_platform_pg = Mock(return_value = True)

        starting_image_count = 2*len(self.dependent_var)
        ending_image_count = starting_image_count + len(self.dependent_var)

        state = [self.loss, self.accuracy, starting_image_count]
        state.extend(self.model_weights)
        state = np.array(state, dtype=np.float32)

        multiplied_weights = mult(self.total_images_per_seg[0],self.model_weights)

        self.subject.compile_and_set_weights(self.model, self.compile_params,
                                             '/cpu:0', state.tostring(), self.model_shapes)
        k = {'SD': { 'model_shapes': self.model_shapes}}
        k['SD']['segment_model'] = self.model
        new_model_state = self.subject.fit_transition(
            state.tostring(), self.independent_var , self.dependent_var, 0, 2, self.all_seg_ids, self.total_images_per_seg,
            self.model.to_json(), None, self.fit_params, False, 'dummy_previous_state', **k)

        state = np.fromstring(new_model_state, dtype=np.float32)
        image_count = state[2]
        weights = np.rint(state[3:]).astype(np.int)
        self.assertEqual(ending_image_count, image_count)
        # weights should be multiplied by final image count
        self.assertTrue((multiplied_weights == weights).all())
        # set_session must be not be called in transition func for PG
        self.assertEqual(0, self.subject.K.set_session.call_count)
        # Clear session and sess.close must get called for the last buffer in gpdb,
        #  but not in postgres
        self.assertEqual(0, self.subject.clear_keras_session.call_count)

    def test_fit_transition_last_buffer_pass_gpdb(self):
        #TODO should we mock tensorflow's close_session and keras'
        # clear_session instead of mocking the function `clear_keras_session`
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()
        self.subject.is_platform_pg = Mock(return_value = False)

        starting_image_count = 2*len(self.dependent_var)
        ending_image_count = starting_image_count + len(self.dependent_var)

        state = [self.loss, self.accuracy, starting_image_count]
        state.extend(self.model_weights)
        state = np.array(state, dtype=np.float32)

        multiplied_weights = mult(self.total_images_per_seg[0],self.model_weights)

        self.subject.compile_and_set_weights(self.model, self.compile_params,
                                             '/cpu:0', state.tostring(), self.model_shapes)
        k = {'SD': { 'model_shapes': self.model_shapes}}
        k['SD']['segment_model'] = self.model
        new_model_state = self.subject.fit_transition(
            state.tostring(), self.independent_var , self.dependent_var, 0, 2, self.all_seg_ids, self.total_images_per_seg,
            self.model.to_json(), None, self.fit_params, False, 'dummy_previous_state', **k)

        state = np.fromstring(new_model_state, dtype=np.float32)
        image_count = state[2]
        weights = np.rint(state[3:]).astype(np.int)
        self.assertEqual(ending_image_count, image_count)
        # weights should be multiplied by final image count
        self.assertTrue((multiplied_weights == weights).all())
        # set_session must get called ONLY once, when its the first buffer
        self.assertEqual(0, self.subject.K.set_session.call_count)
        # Clear session and sess.close must get called for the last buffer in gpdb,
        #  but not in postgres
        self.assertEqual(1, self.subject.clear_keras_session.call_count)

    def test_fit_transition_too_many_images(self):
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()
        starting_image_count = 0
        previous_state = [self.loss, self.accuracy, starting_image_count]
        previous_state.extend(self.model_weights)
        previous_state = np.array(previous_state, dtype=np.float32)

        k = {'SD' : {}}

        total_images_per_seg = [1,1,1]

        with self.assertRaises(plpy.PLPYException):
            new_model_state = self.subject.fit_transition(
            None, self.independent_var , self.dependent_var, 0, 2, self.all_seg_ids, total_images_per_seg,
            self.model.to_json(), self.compile_params, self.fit_params, False,
            previous_state.tostring(), **k)


    def test_fit_merge(self):
        image_count = self.total_images_per_seg[0]
        state1 = [3.0*self.loss, 3.0*self.accuracy, image_count]
        state1.extend(mult(3,self.model_weights))
        state1 = np.array(state1, dtype=np.float32)
        state2 = [2.0*self.loss, 2.0*self.accuracy, image_count+30]
        state2.extend(mult(2,self.model_weights))
        state2 = np.array(state2, dtype=np.float32)
        merged_state = self.subject.fit_merge(state1.tostring(),state2.tostring())
        state = np.fromstring(merged_state, dtype=np.float32)
        agg_loss = state[0]
        agg_accuracy = state[1]
        image_count_total = state[2]
        weights = np.rint(state[3:]).astype(np.int)

        self.assertEqual( 2*image_count+30 , image_count_total )
        self.assertAlmostEqual( 5.0*self.loss, agg_loss, 2)
        self.assertAlmostEqual( 5.0*self.accuracy, agg_accuracy, 2)
        self.assertTrue( (mult(5,self.model_weights) == weights).all())

    def test_fit_merge_none_first(self):
        image_count = self.total_images_per_seg[0]
        input_state = [self.loss, self.accuracy, image_count]
        input_state.extend(self.model_weights)
        input_state = np.array(input_state, dtype=np.float32)
        merged_state = self.subject.fit_merge(None, input_state.tostring())
        state = np.fromstring(merged_state, dtype=np.float32)
        agg_loss = state[0]
        agg_accuracy = state[1]
        image_count_total = state[2]
        weights = np.rint(state[3:]).astype(np.int)

        self.assertEqual(image_count, image_count_total)
        self.assertAlmostEqual(self.loss, agg_loss, 2)
        self.assertAlmostEqual(self.accuracy, agg_accuracy, 2)
        self.assertTrue((self.model_weights == weights).all())

    def test_fit_merge_none_second(self):
        image_count = self.total_images_per_seg[0]
        input_state = [self.loss, self.accuracy, image_count]
        input_state.extend(self.model_weights)
        input_state = np.array(input_state, dtype=np.float32)
        merged_state = self.subject.fit_merge(input_state.tostring(), None)
        state = np.fromstring(merged_state, dtype=np.float32)
        agg_loss = state[0]
        agg_accuracy = state[1]
        image_count_total = state[2]
        weights = np.rint(state[3:]).astype(np.int)

        self.assertEqual(image_count, image_count_total)
        self.assertAlmostEqual(self.loss, agg_loss, 2)
        self.assertAlmostEqual(self.accuracy, agg_accuracy, 2)
        self.assertTrue((self.model_weights == weights).all())

    def test_fit_merge_both_none(self):
        result = self.subject.fit_merge(None,None)
        self.assertEqual(None, result)

    def test_fit_final(self):
        image_count = self.total_images_per_seg[0]
        input_state = [image_count*self.loss, image_count*self.accuracy, image_count]
        input_state.extend(mult(image_count,self.model_weights))
        input_state = np.array(input_state, dtype=np.float32)

        output_state = self.subject.fit_final(input_state.tostring())
        output_state = np.fromstring(output_state, dtype=np.float32)
        agg_loss = output_state[0]
        agg_accuracy = output_state[1]
        image_count_output = output_state[2]
        weights = np.rint(output_state[3:]).astype(np.int)

        self.assertEqual(image_count, image_count_output)
        self.assertAlmostEqual(self.loss, agg_loss,2)
        self.assertAlmostEqual(self.accuracy, agg_accuracy,2)
        self.assertTrue((self.model_weights == weights).all())

    def test_fit_final_none(self):
        result = self.subject.fit_final(None)
        self.assertEqual(result, None)

    def test_fit_final_image_count_zero(self):
        input_state = [0, 0, 0]
        input_state.extend(self.model_weights)
        input_state = np.array(input_state, dtype=np.float32)

        with self.assertRaises(plpy.PLPYException):
            result = self.subject.fit_final(input_state.tostring())


    def test_get_device_name_and_set_cuda_env(self):
        import os
        self.assertEqual('/gpu:0', self.subject.get_device_name_and_set_cuda_env(
            True, 1))
        self.assertEqual('1', os.environ["CUDA_VISIBLE_DEVICES"])
        self.assertEqual('/cpu:0', self.subject.get_device_name_and_set_cuda_env(
            False, 1))
        self.assertEqual('-1', os.environ["CUDA_VISIBLE_DEVICES"])

    def test_fit_transition_first_tuple_none_ind_var_dep_var(self):
        k = {}
        self.assertEqual('dummy_state',
            self.subject.fit_transition('dummy_state', None , [0], 1, 2,
            [0,1,2], [3,3,3], 'dummy_model_json', "foo", "bar", False,
            'dummy_prev_state', **k))
        self.assertEqual('dummy_state',
            self.subject.fit_transition('dummy_state', [[0.5]], None, 1, 2,
            [0,1,2], [3,3,3], 'dummy_model_json', "foo", "bar", False,
            'dummy_prev_state', **k))
        self.assertEqual('dummy_state',
            self.subject.fit_transition('dummy_state', None, None, 1, 2,
            [0,1,2], [3,3,3], 'dummy_model_json', "foo", "bar", False,
            'dummy_prev_state', **k))

    def test_split_and_strip(self):
        self.assertEqual(('a','b'), self.subject.split_and_strip(' a = b '))

    def test_parse_and_validate_fit_params(self):
        result = {'batch_size':2, 'epochs':1, 'verbose':0}
        self.assertDictEqual(result, self.subject.parse_and_validate_fit_params('batch_size=2, epochs=1, verbose=0'))

    def test_parse_optimizer(self):

        import keras.losses as losses

        loss_func = losses.categorical_crossentropy
        compile_dict = {'loss':'losses.categorical_crossentropy'}
        self.assertEqual(self.subject.parse_loss(compile_dict), loss_func)

    def test_parse_loss(self):
        opt_name = 'SGD'
        final_args = {'lr':0.01, 'decay':1e-6, 'nesterov':True}
        compile_dict = {}
        compile_dict['optimizer']='SGD(lr=0.01, decay=1e-6, nesterov=True)'
        result_name, result_params = self.subject.parse_optimizer(compile_dict)

        self.assertEqual(result_name, opt_name)
        self.assertDictEqual(result_params, final_args)

    def test_parse_and_validate_compile_params(self):

        test_str = "optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy']"
        compile_dict = {'optimizer':'SGD(lr=0.01, decay=1e-6, nesterov=True)', 'metrics':['accuracy'], 'loss':'categorical_crossentropy'}
        opt_name,opt_args,result_params = self.subject.parse_and_validate_compile_params(test_str)
        self.assertDictEqual(result_params, compile_dict)

    def test_parse_and_validate_fit_params(self):

        test_str = "batch_size=2, epochs=1, verbose=0"
        fit_dict = {'batch_size':2, 'epochs':1, 'verbose':0}
        result_params = self.subject.parse_and_validate_fit_params(test_str)
        self.assertDictEqual(result_params, fit_dict)

    def test_validate_and_literal_eval_keys(self):

        test_dict = {'batch_size':'2', 'epochs':'1', 'verbose':'0'}
        target_dict = {'batch_size':2, 'epochs':1, 'verbose':0}
        literal_eval_fit_params = ['batch_size','epochs','verbose','shuffle',
                           'class_weight','initial_epoch','steps_per_epoch']
        accepted_fit_params = literal_eval_fit_params + ['shuffle']
        result_params = self.subject.validate_and_literal_eval_keys(
                            test_dict,
                            literal_eval_fit_params,
                            accepted_fit_params)
        self.assertDictEqual(result_params, target_dict)

## Negative Tests
    def test_parse_and_validate_compile_params_dict_metrics_fail(self):
        test_str = "optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True), loss='categorical_crossentropy', metrics={'0':'accuracy'}"

        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_compile_params(test_str)

    def test_parse_and_validate_compile_params_tensor_loss_weights_fail(self):

        test_str = "optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'], loss_weights = keras.layers.Input(shape=(32,))"

        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_compile_params(test_str)


    def test_parse_and_validate_compile_params_list_dict_sample_weight_mode_fail(self):
        test_str = "optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode = [0,1]"

        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_compile_params(test_str)

        test_str = "optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode = {'0':'1'}"

        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_compile_params(test_str)


    def test_parse_and_validate_compile_params_target_tensors_fail(self):
        test_str = "optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy'], target_tensors = keras.layers.Input(shape=(32,))"

        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_compile_params(test_str)

    def test_parse_and_validate_fit_params_callbacks_fail(self):

        test_str = "batch_size=2, epochs=1, verbose=0, callbacks=keras.callbacks.Callback()"
        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_fit_params(test_str)

    def test_parse_and_validate_fit_params_validation_split_fail(self):

        test_str = "batch_size=2, epochs=1, verbose=0, validation_split=0.1"
        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_fit_params(test_str)

    def test_parse_and_validate_fit_params_validation_data_fail(self):

        test_str = "batch_size=2, epochs=1, verbose=0, validation_data=(1,2,3)"
        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_fit_params(test_str)

    def test_parse_and_validate_fit_params_sample_weight_fail(self):

        test_str = "batch_size=2, epochs=1, verbose=0, sample_weight=np.array([1,2,3])"
        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_fit_params(test_str)

    def test_parse_and_validate_fit_params_validation_steps_fail(self):

        test_str = "batch_size=2, epochs=1, verbose=0, validation_steps=1"
        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_fit_params(test_str)

    def test_parse_and_validate_fit_params_validation_freq_fail(self):

        test_str = "batch_size=2, epochs=1, verbose=0, validation_freq=1"
        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_fit_params(test_str)

        test_str = "batch_size=2, epochs=1, verbose=0, validation_freq=[1]"
        with self.assertRaises(plpy.PLPYException):
            self.subject.parse_and_validate_fit_params(test_str)

class MadlibKerasValidatorTestCase(unittest.TestCase):
    def setUp(self):
        self.plpy_mock = Mock(spec='error')
        patches = {
            'plpy': plpy
        }

        self.plpy_mock_execute = MagicMock()
        plpy.execute = self.plpy_mock_execute

        self.module_patcher = patch.dict('sys.modules', patches)
        self.module_patcher.start()
        import madlib_keras_validator
        self.subject = madlib_keras_validator

    def tearDown(self):
        self.module_patcher.stop()

    def test_validate_input_shapes_shapes_do_not_match(self):
        self.plpy_mock_execute.return_value = [{'n_0': 32, 'n_1': 32}]
        self.subject._validate_input_args = Mock()
        with self.assertRaises(plpy.PLPYException):
            self.subject._validate_input_shapes(
                'dummy_tbl', 'dummy_col', [32,32,3], 2)

        self.plpy_mock_execute.return_value = [{'n_0': 3, 'n_1': 32, 'n_2': 32}]
        with self.assertRaises(plpy.PLPYException):
            self.subject._validate_input_shapes(
                'dummy_tbl', 'dummy_col', [32,32,3], 2)

        self.plpy_mock_execute.return_value = [{'n_0': 3, 'n_1': None, 'n_2': None}]
        with self.assertRaises(plpy.PLPYException):
            self.subject._validate_input_shapes(
                'dummy_tbl', 'dummy_col', [3,32], 2)

    def test_validate_input_shapes_shapes_match(self):
        self.plpy_mock_execute.return_value = [{'n_0': 32, 'n_1': 32, 'n_2': 3}]
        self.subject._validate_input_args = Mock()
        self.subject._validate_input_shapes(
            'dummy_tbl', 'dummy_col', [32,32,3], 1)

class MadlibSerializerTestCase(unittest.TestCase):
    def setUp(self):
        self.plpy_mock = Mock(spec='error')
        patches = {
            'plpy': plpy
        }

        self.plpy_mock_execute = MagicMock()
        plpy.execute = self.plpy_mock_execute

        self.module_patcher = patch.dict('sys.modules', patches)
        self.module_patcher.start()
        import madlib_keras_serializer
        self.subject = madlib_keras_serializer

    def tearDown(self):
        self.module_patcher.stop()

    def test_deserialize_weights_merge_null_state_returns_none(self):
        self.assertEqual(None, self.subject.deserialize_weights_merge(None))

    def test_deserialize_weights_merge_returns_not_none(self):
        dummy_model_state = np.array([0,1,2,3,4,5,6], dtype=np.float32)
        res = self.subject.deserialize_weights_merge(dummy_model_state.tostring())
        self.assertEqual(0, res[0])
        self.assertEqual(1, res[1])
        self.assertEqual(2, res[2])
        self.assertEqual([3,4,5,6], res[3].tolist())

    def test_deserialize_weights_null_input_returns_none(self):
        dummy_model_state = np.array([0,1,2,3,4,5,6], dtype=np.float32)
        self.assertEqual(None, self.subject.deserialize_weights(dummy_model_state.tostring(), None))
        self.assertEqual(None, self.subject.deserialize_weights(None, [1,2,3]))
        self.assertEqual(None, self.subject.deserialize_weights(None, None))

    def test_deserialize_weights_valid_input_returns_not_none(self):
        dummy_model_state = np.array([0,1,2,3,4,5], dtype=np.float32)
        dummy_model_shape = [(2, 1, 1, 1), (1,)]
        res = self.subject.deserialize_weights(dummy_model_state.tostring(), dummy_model_shape)
        self.assertEqual(0, res[0])
        self.assertEqual(1, res[1])
        self.assertEqual(2, res[2])
        self.assertEqual([[[[3.0]]], [[[4.0]]]], res[3][0].tolist())
        self.assertEqual([5], res[3][1].tolist())

    def test_deserialize_weights_invalid_input_fails(self):
        # pass an invalid state with missing model weights
        invalid_model_state = np.array([0,1,2], dtype=np.float32)
        dummy_model_shape = [(2, 1, 1, 1), (1,)]

        # we expect keras failure(ValueError) because we cannot reshape
        # model weights of size 0 into shape (2,2,3,1)
        with self.assertRaises(ValueError):
            self.subject.deserialize_weights(invalid_model_state.tostring(), dummy_model_shape)

        invalid_model_state = np.array([0,1,2,3,4], dtype=np.float32)
        dummy_model_shape = [(2, 2, 3, 1), (1,)]
        # we expect keras failure(ValueError) because we cannot reshape
        # model weights of size 2 into shape (2,2,3,1)
        with self.assertRaises(ValueError):
            self.subject.deserialize_weights(invalid_model_state.tostring(), dummy_model_shape)

    def test_deserialize_iteration_state_none_input_returns_none(self):
        self.assertEqual(None, self.subject.deserialize_iteration_state(None))

    def test_deserialize_iteration_state_returns_valid_output(self):
        dummy_iteration_state = np.array([0,1,2,3,4,5], dtype=np.float32)
        res = self.subject.deserialize_iteration_state(
            dummy_iteration_state.tostring())
        self.assertEqual(0, res[0])
        self.assertEqual(1, res[1])
        self.assertEqual(res[2],
                         np.array([0,0,0,3,4,5], dtype=np.float32).tostring())

    def test_serialize_weights_none_weights_returns_none(self):
        res = self.subject.serialize_weights(0,1,2,None)
        self.assertEqual(None , res)

    def test_serialize_weights_valid_output(self):
        res = self.subject.serialize_weights(0,1,2,[np.array([1,3]),
                                                    np.array([4,5])])
        self.assertEqual(np.array([0,1,2,1,3,4,5], dtype=np.float32).tostring(),
                         res)

    def test_serialize_weights_merge_none_weights_returns_none(self):
        res = self.subject.serialize_weights_merge(0,1,2,None)
        self.assertEqual(None , res)

    def test_serialize_weights_merge_valid_output(self):
        res = self.subject.serialize_weights_merge(0,1,2,np.array([1,3,4,5]))
        self.assertEqual(np.array([0,1,2,1,3,4,5], dtype=np.float32).tostring(),
                         res)

class PredictInputPredTypeValidationTestCase(unittest.TestCase):
    def setUp(self):
        self.plpy_mock = Mock(spec='error')
        patches = {
            'plpy': plpy
        }

        self.plpy_mock_execute = MagicMock()
        plpy.execute = self.plpy_mock_execute

        self.module_patcher = patch.dict('sys.modules', patches)
        self.module_patcher.start()
        import madlib_keras_validator
        self.module = madlib_keras_validator
        self.module.PredictInputValidator._validate_input_args = Mock()
        self.subject = self.module.PredictInputValidator(
            'test_table', 'model_table', 'id_col', 'independent_varname',
            'output_table', 'pred_type', 'module_name')
        self.classes = ['train', 'boat', 'car', 'airplane']

    def tearDown(self):
        self.module_patcher.stop()

    def test_validate_pred_type_invalid_pred_type(self):
        self.subject.pred_type = 'invalid'
        with self.assertRaises(plpy.PLPYException):
            self.subject.validate_pred_type(['cat', 'dog'])

    def test_validate_pred_type_valid_pred_type_invalid_num_class_values(self):
        self.subject.pred_type = 'prob'
        with self.assertRaises(plpy.PLPYException):
            self.subject.validate_pred_type(range(1599))

    def test_validate_pred_type_valid_pred_type_valid_class_values_prob(self):
        self.subject.pred_type = 'prob'
        self.subject.validate_pred_type(range(1598))
        self.subject.validate_pred_type(None)

    def test_validate_pred_type_valid_pred_type_valid_class_values_response(self):
        self.subject.pred_type = 'response'
        self.subject.validate_pred_type(range(1598))
        self.subject.validate_pred_type(None)

class MadlibKerasPredictTestCase(unittest.TestCase):
    def setUp(self):
        self.plpy_mock = Mock(spec='error')
        patches = {
            'plpy': plpy
        }

        self.plpy_mock_execute = MagicMock()
        plpy.execute = self.plpy_mock_execute

        self.module_patcher = patch.dict('sys.modules', patches)
        self.module_patcher.start()
        import madlib_keras_predict
        self.subject = madlib_keras_predict

    def tearDown(self):
        self.module_patcher.stop()

    def test_strip_trailing_nulls_from_class_values(self):
        self.assertEqual(['cat', 'dog'],
                         self.subject._strip_trailing_nulls_from_class_values(
                ['cat', 'dog']))
        self.assertEqual([None, 'cat', 'dog'],
                         self.subject._strip_trailing_nulls_from_class_values(
                [None, 'cat', 'dog']))
        self.assertEqual([None, 'cat', 'dog'],
                         self.subject._strip_trailing_nulls_from_class_values(
                [None, 'cat', 'dog', None, None]))
        self.assertEqual(['cat', 'dog'],
                         self.subject._strip_trailing_nulls_from_class_values(
                ['cat', 'dog', None, None]))
        self.assertEqual([None],
                         self.subject._strip_trailing_nulls_from_class_values(
                [None, None]))

class MadlibKerasHelperTestCase(unittest.TestCase):
    def setUp(self):
        self.plpy_mock = Mock(spec='error')
        patches = {
            'plpy': plpy
        }

        self.plpy_mock_execute = MagicMock()
        plpy.execute = self.plpy_mock_execute

        self.module_patcher = patch.dict('sys.modules', patches)
        self.module_patcher.start()
        import madlib_keras_helper
        self.subject = madlib_keras_helper
        self.input_data = [32, 32, 3]

    def tearDown(self):
        self.module_patcher.stop()

    def test_expand_input_dims(self):
        self.assertEqual(np.array(self.input_data).shape, (3,))
        res = self.subject.expand_input_dims(self.input_data)
        self.assertEqual(res.shape, (1, 3))

class MadlibKerasEvaluationTestCase(unittest.TestCase):
    def setUp(self):
        print("Setting up...")
        self.plpy_mock = Mock(spec='error')
        patches = {
            'plpy': plpy
        }

        self.plpy_mock_execute = MagicMock()
        plpy.execute = self.plpy_mock_execute

        self.module_patcher = patch.dict('sys.modules', patches)
        self.module_patcher.start()
        import madlib_keras
        self.subject = madlib_keras

        self.model = Sequential()
        self.model.add(Conv2D(2, kernel_size=(1, 1), activation='relu',
                         input_shape=(1,1,1,), padding='same'))
        self.model.add(Flatten())

        self.compile_params = "optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True), loss='categorical_crossentropy', metrics=['accuracy']"
        self.model_weights = [3,4,5,6]
        self.model_shapes = []
        for a in self.model.get_weights():
            self.model_shapes.append(a.shape)

        self.loss = 0.5947071313858032
        self.accuracy = 1.0
        self.all_seg_ids = [0,1,2]

        #self.model.evaluate = Mock(return_value = [self.loss, self.accuracy])

        self.independent_var = [[[[0.5]]]] * 10
        self.dependent_var = [[0,1]] * 10
        # We test on segment 0, which has 3 buffers filled with 10 identical
        #  images each, or 30 images total
        self.total_images_per_seg = [3*len(self.dependent_var),20,40]

    def tearDown(self):
        self.module_patcher.stop()

    def _test_internal_keras_eval_transition_first_buffer(self, is_platform_pg):
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()
        self.subject.is_platform_pg = Mock(return_value = False)
        starting_image_count = 0
        ending_image_count = len(self.dependent_var)

        k = {'SD' : {}}
        state = [0,0,0]

        serialized_weights = [0, 0, 0] # not used
        serialized_weights.extend(self.model_weights)
        serialized_weights = np.array(serialized_weights, dtype=np.float32).tostring()

        new_state = self.subject.internal_keras_eval_transition(
            state, self.dependent_var , self.independent_var, self.model.to_json(), serialized_weights,
            self.compile_params, is_platform_pg, self.all_seg_ids, self.total_images_per_seg,
            0, **k)

        agg_loss, agg_accuracy, image_count = new_state

        self.assertEqual(ending_image_count, image_count)
        # set_session must get called ONLY once, when its the first buffer
        self.assertEqual(1, self.subject.K.set_session.call_count)
        # loss and accuracy should be unchanged
        self.assertAlmostEqual(self.loss * image_count, agg_loss, 4)
        self.assertAlmostEqual(self.accuracy * image_count, agg_accuracy, 4)
        # Clear session and sess.close must not get called for the first buffer
        self.assertEqual(0, self.subject.clear_keras_session.call_count)
        self.assertTrue(k['SD']['segment_model'])

    def _test_internal_keras_eval_transition_middle_buffer(self, is_platform_pg):
        #TODO should we mock tensorflow's close_session and keras'
        # clear_session instead of mocking the function `clear_keras_session`
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()
        self.subject.is_platform_pg = Mock(return_value = False)

        starting_image_count = len(self.dependent_var)
        ending_image_count = starting_image_count + len(self.dependent_var)

        k = {'SD' : {}}

        model_state = [self.loss, self.accuracy, starting_image_count]
        model_state.extend(self.model_weights)
        model_state = np.array(model_state, dtype=np.float32)

        self.subject.compile_and_set_weights(self.model, self.compile_params,
                                             '/cpu:0', model_state.tostring(), self.model_shapes)

        state = [self.loss * starting_image_count, self.accuracy * starting_image_count, starting_image_count]
        k['SD']['segment_model'] = self.model

        new_state = self.subject.internal_keras_eval_transition(
            state, self.dependent_var , self.independent_var, self.model.to_json(), 'dummy_model_data',
            None, is_platform_pg, self.all_seg_ids, self.total_images_per_seg,
            0, **k)

        agg_loss, agg_accuracy, image_count = new_state

        self.assertEqual(ending_image_count, image_count)
        # set_session must get called ONLY once, when its the first buffer
        self.assertEqual(0, self.subject.K.set_session.call_count)
         # loss and accuracy should be unchanged
        self.assertAlmostEqual(self.loss * ending_image_count, agg_loss, 4)
        self.assertAlmostEqual(self.accuracy * ending_image_count, agg_accuracy, 4)
        # Clear session and sess.close must not get called for the middle buffer
        self.assertEqual(0, self.subject.clear_keras_session.call_count)

    def _test_internal_keras_eval_transition_last_buffer(self, is_platform_pg):
        #TODO should we mock tensorflow's close_session and keras'
        # clear_session instead of mocking the function `clear_keras_session`
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()
        self.subject.is_platform_pg = Mock(return_value = False)

        starting_image_count = 2*len(self.dependent_var)
        ending_image_count = starting_image_count + len(self.dependent_var)
        k = {'SD' : {}}

        model_state = [self.loss, self.accuracy, starting_image_count]
        model_state.extend(self.model_weights)
        model_state = np.array(model_state, dtype=np.float32)

        self.subject.compile_and_set_weights(self.model, self.compile_params,
                                             '/cpu:0', model_state.tostring(), self.model_shapes)

        state = [self.loss * starting_image_count, self.accuracy * starting_image_count, starting_image_count]

        k['SD']['segment_model'] = self.model
        new_state = self.subject.internal_keras_eval_transition(
            state, self.dependent_var , self.independent_var, self.model.to_json(), 'dummy_model_data',
            None, is_platform_pg, self.all_seg_ids, self.total_images_per_seg,
            0, **k)

        agg_loss, agg_accuracy, image_count = new_state

        self.assertEqual(ending_image_count, image_count)
        # set_session must get called ONLY once, when its the first buffer
        self.assertEqual(0, self.subject.K.set_session.call_count)
        # loss and accuracy should be unchanged
        self.assertAlmostEqual(self.loss * ending_image_count, agg_loss, 4)
        self.assertAlmostEqual(self.accuracy * ending_image_count, agg_accuracy, 4)
        # Clear session and sess.close must get called for the last buffer in gpdb,
        #  but not in postgres
        self.assertEqual(1, self.subject.clear_keras_session.call_count)

    def test_internal_keras_eval_transition_first_buffer_pg(self):
        self._test_internal_keras_eval_transition_first_buffer(True)

    def test_internal_keras_eval_transition_first_buffer_gpdb(self):
        self._test_internal_keras_eval_transition_first_buffer(False)

    def test_internal_keras_eval_transition_middle_buffer_pg(self):
        self._test_internal_keras_eval_transition_middle_buffer(True)

    def test_internal_keras_eval_transition_middle_buffer_gpdb(self):
        self._test_internal_keras_eval_transition_middle_buffer(False)

    def test_internal_keras_eval_transition_last_buffer_pg(self):
        self._test_internal_keras_eval_transition_last_buffer(True)

    def test_internal_keras_eval_transition_last_buffer_gpdb(self):
        self._test_internal_keras_eval_transition_last_buffer(False)

    def test_internal_keras_eval_merge(self):
        image_count = self.total_images_per_seg[0]
        state1 = [3.0*self.loss, 3.0*self.accuracy, image_count]
        state1 = state1
        state2 = [2.0*self.loss, 2.0*self.accuracy, image_count+30]
        state2 = state2
        merged_state = self.subject.internal_keras_eval_merge(state1,state2)
        state = merged_state
        agg_loss = state[0]
        agg_accuracy = state[1]
        image_count_total = state[2]

        self.assertEqual( 2*image_count+30 , image_count_total )
        self.assertAlmostEqual( 5.0*self.loss, agg_loss, 2)
        self.assertAlmostEqual( 5.0*self.accuracy, agg_accuracy, 2)

    def test_internal_keras_eval_merge_none_first(self):
        image_count = self.total_images_per_seg[0]
        input_state = [self.loss, self.accuracy, image_count]
        merged_state = self.subject.internal_keras_eval_merge(None, input_state)
        agg_loss = merged_state[0]
        agg_accuracy = merged_state[1]
        image_count_total = merged_state[2]

        self.assertEqual(image_count, image_count_total)
        self.assertAlmostEqual(self.loss, agg_loss, 2)
        self.assertAlmostEqual(self.accuracy, agg_accuracy, 2)

    def test_internal_keras_eval_merge_none_second(self):
        image_count = self.total_images_per_seg[0]
        input_state = [self.loss, self.accuracy, image_count]
        merged_state = self.subject.internal_keras_eval_merge(input_state, None)
        agg_loss = merged_state[0]
        agg_accuracy = merged_state[1]
        image_count_total = merged_state[2]

        self.assertEqual(image_count, image_count_total)
        self.assertAlmostEqual(self.loss, agg_loss, 2)
        self.assertAlmostEqual(self.accuracy, agg_accuracy, 2)

    def test_internal_keras_eval_merge_both_none(self):
        result = self.subject.internal_keras_eval_merge(None,None)
        self.assertEqual(None, result)

    def test_internal_keras_eval_final(self):
        image_count = self.total_images_per_seg[0]
        input_state = [image_count*self.loss, image_count*self.accuracy, image_count]

        output_state = self.subject.internal_keras_eval_final(input_state)
        agg_loss = output_state[0]
        agg_accuracy = output_state[1]
        image_count_output = output_state[2]

        self.assertEqual(image_count, image_count_output)
        self.assertAlmostEqual(self.loss, agg_loss,2)
        self.assertAlmostEqual(self.accuracy, agg_accuracy,2)

    def internal_keras_eval_final_none(self):
        result = self.subject.internal_keras_eval_final(None)
        self.assertEqual(result, None)

    def test_internal_keras_eval_transition_too_many_images(self):
        self.subject.K.set_session = Mock()
        self.subject.clear_keras_session = Mock()

        starting_image_count = 5

        k = {'SD' : {}}
        model_state = [self.loss, self.accuracy, starting_image_count]
        model_state.extend(self.model_weights)
        model_state = np.array(model_state, dtype=np.float32)

        self.subject.compile_and_set_weights(self.model, self.compile_params,
                                             '/cpu:0', model_state.tostring(), self.model_shapes)

        state = [self.loss * starting_image_count, self.accuracy * starting_image_count, starting_image_count]

        k['SD']['segment_model'] = self.model

        total_images_per_seg = [10, 10, 10]

        with self.assertRaises(plpy.PLPYException):
            self.subject.internal_keras_eval_transition(
                state, self.dependent_var , self.independent_var, self.model.to_json(), 'dummy_model_data',
                None, False, self.all_seg_ids, total_images_per_seg,
                0, **k)

    def test_internal_keras_eval_final_image_count_zero(self):
        input_state = [0, 0, 0]

        with self.assertRaises(plpy.PLPYException):
            result = self.subject.internal_keras_eval_final(input_state)

if __name__ == '__main__':
    unittest.main()
# ---------------------------------------------------------------------
